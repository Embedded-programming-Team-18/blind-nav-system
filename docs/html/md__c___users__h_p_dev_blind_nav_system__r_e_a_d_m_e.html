<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.3"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Blind Navigation System: Navigation System for Blind People - &lt;tt&gt;Smart Glove&lt;/tt&gt;</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="smart_glove_3.jpg"/></td>
  <td id="projectalign">
   <div id="projectname">Blind Navigation System
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.3 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search",'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div><div class="header">
  <div class="headertitle"><div class="title">Navigation System for Blind People - <code>Smart Glove</code> </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p >This project involves the development of an assistive smart glove using Light Detection and Ranging(LiDAR) technology and <code>Raspbery pi</code> to help individuals who are blind or with low vision to navigate with confidence. It contributes a <code>C++ library for TFMini s sensor</code> and use it in the development the hand glove.</p>
<h1><a class="anchor" id="autotoc_md7"></a>
Status</h1>
<p ><a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License: MIT" style="pointer-events: none;" class="inline"/></a> <a href="https://github.com/EvelynAnyebe/blind-nav-system"><img src="https://img.shields.io/github/contributors/EvelynAnyebe/blind-nav-system" alt="Contributors" class="inline"/></a> <a href="https://github.com/EvelynAnyebe/blind-nav-system/issues"><img src="https://img.shields.io/github/issues-raw/EvelynAnyebe/blind-nav-system" alt="Open Issues" class="inline"/></a> <a href="https://github.com/EvelynAnyebe/blind-nav-system"><img src="https://img.shields.io/github/issues-closed-raw/EvelynAnyebe/blind-nav-system" alt="Closed Issues" class="inline"/></a> <a href="https://github.com/EvelynAnyebe/blind-nav-system"><img src="https://img.shields.io/github/issues-pr/EvelynAnyebe/blind-nav-system" alt="PR" class="inline"/></a> <a href="https://github.com/EvelynAnyebe/blind-nav-system"><img src="https://img.shields.io/github/milestones/all/EvelynAnyebe/blind-nav-system" alt="Milestones" class="inline"/></a> <a href="https://github.com/EvelynAnyebe/blind-nav-system"><img src="https://img.shields.io/github/languages/code-size/EvelynAnyebe/blind-nav-system" alt="Code Size" class="inline"/></a></p>
<h1><a class="anchor" id="autotoc_md8"></a>
Table of Contents</h1>
<ul>
<li>Motivation</li>
<li>Hardware Requirements</li>
<li>Software Development</li>
<li>Installation</li>
<li>Tests</li>
<li>How to Use</li>
<li>Contributing Guide</li>
<li>Social Media</li>
<li>Credits</li>
<li>Reference Links</li>
</ul>
<h1><a class="anchor" id="autotoc_md9"></a>
Motivation</h1>
<p >There are many assistive technologies that aid blind people navigate their enviroment. These can be in eye glasses, walking canes, helmets etc. However, the usefulness of these devices are still in debate mbecause they are usually combined with guide dogs and canes.</p>
<p >Here a smart glove program is developed to tackle the navigation problem for blind people so that they can be confident to move without a cane or guide dog. <a href="https://embedded-programming-team-18.github.io/blind-nav-system/">Find out more on our GitHub page here</a></p>
<p ><img src="https://res.cloudinary.com/dxsty3st6/image/upload/v1643001489/blind-nav-system/smart_glove_3_pxaxcr.jpg" alt="smart hand glove to help blind people navigate" class="inline"/></p>
<div class="fragment"><div class="line">**Why Smart Glove?**</div>
<div class="line">1. Good for mobility as it is more compact.</div>
<div class="line"> </div>
<div class="line">2. Flexible for position of a person.</div>
<div class="line"> </div>
<div class="line">3. Ease of use than cane.</div>
<div class="line"> </div>
<div class="line">4. More range than the stick.</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md10"></a>
Hardware Requirements</h1>
<p ><img src="https://res.cloudinary.com/dxsty3st6/image/upload/v1649396693/blind-nav-system/icons8-raspberry-pi-48_wvkoak.png" alt="raspberry pi" class="inline"/></p>
<p >The main componenents used for this project are:</p>
<div class="fragment"><div class="line">* Raspberry Pi 4</div>
<div class="line">* TFMini S LiDAR sensor</div>
<div class="line">* Servo motto</div>
<div class="line">* 5 mottos</div>
<div class="line">* Logic Converter</div>
</div><!-- fragment --><p ><img src="https://res.cloudinary.com/dxsty3st6/image/upload/v1649389827/blind-nav-system/Schematic-diagram-image_ty0cjs.jpg" alt="Schematic Diagram of the blind navigation system" class="inline"/></p>
<p >The servo motto board was coupled by the team and LEDs were used during the development stage. Logic converters were used to step-down voltage from +5V to +3V needed by the <a class="el" href="class_lidar.html" title="The LiDAR class is a low-level driver for obtaining distance values needed for the functioning of the...">Lidar</a>. The schematic diagram of the project is subject on changes. For instance, when using LEDs for the prototype <code>resistors</code> were added. <a href="https://www.instagram.com/p/CcE22h5jnIw/">You can view this prototype here</a>. The image gallery can be viewed on <a href="https://www.instagram.com/blindnavsystem/">instagram</a></p>
<h1><a class="anchor" id="autotoc_md11"></a>
Software Development</h1>
<p ><img src="https://res.cloudinary.com/dxsty3st6/image/upload/v1649395304/blind-nav-system/c_-48_mbi1wr.png" alt="C++ Icon" class="inline"/> <img src="https://res.cloudinary.com/dxsty3st6/image/upload/v1649395859/blind-nav-system/icons8-visual-studio-48_ss52sr.png" alt="Vscode icon" class="inline"/></p>
<p >This work followed Agile development approach. The various stages of the development process are outlined in order for simplicity.</p>
<p ><b>Requirement Analysis</b></p>
<div class="fragment"><div class="line">* The LIDAR sensor(rotated by a servo motor) makes a map of 90o in front of the person.</div>
<div class="line"> </div>
<div class="line">* According to the map, distance of the obstacles is calculated and returned.</div>
<div class="line"> </div>
<div class="line">* Using that feedback, PWM is sent to a finger.</div>
<div class="line">  Depending on the level of vibration on the fingers,</div>
<div class="line">  the person gets an idea of where the obstacle is located, and he can go left or right.</div>
</div><!-- fragment --><p ><img src="https://res.cloudinary.com/dxsty3st6/image/upload/v1649998685/blind-nav-system/field-of-view-split-in-5_vsp8rx.jpg" alt="Image of the lidar full scan split" class="inline"/></p>
<p >A full scan of the LiDAR (90 degrees) split into 5 directions to guide the user. This is implemented in <code><a class="el" href="main_8cpp.html">main.cpp</a></code> where the driver is used</p>
<p ><b>Software Design</b></p>
<p >In this section an overview of the software design is shown through use case diagrams, state diagrams, sequence diagrams.</p>
<ul>
<li><p class="startli">Use cases</p>
<p class="startli"><img src="https://res.cloudinary.com/dxsty3st6/image/upload/v1650001317/blind-nav-system/blind-man-use-case_v94lsr.jpg" alt="smart glove use case of the lidar driver" class="inline"/></p>
<p class="startli">In this work, a blind navigation system as a smart glove is demonstrated with the LiDAR driver. The driver can be used for other use cases as well.</p>
<p class="startli"><img src="https://res.cloudinary.com/dxsty3st6/image/upload/v1650001331/blind-nav-system/robot-use-case_c97yjf.jpg" alt="A mobile robot use case of the lidar driver" class="inline"/></p>
</li>
<li><p class="startli">State Diagrams</p>
<p class="startli">The state diagram below shows the state changes of the <code>smart glove</code> application.</p>
<p class="startli"><img src="https://res.cloudinary.com/dxsty3st6/image/upload/v1649998685/blind-nav-system/State-diagram-class-diagram_nglqel.jpg" alt="State diagram for the smart glove" class="inline"/></p>
<p class="startli">The state diagram for the lidar object running as a thread is displayed below.</p>
<p class="startli"><img src="https://res.cloudinary.com/dxsty3st6/image/upload/v1649998685/blind-nav-system/lidar-thread-state-diagram_gfo9hg.jpg" alt="State diagram for the liDAR thread" class="inline"/></p>
</li>
<li>Class Diagrams</li>
<li>Sequence Diagrams</li>
</ul>
<p ><b>Development</b></p>
<p ><code>c++</code> <code>CMAKE</code> <code>DOXYGEN</code></p>
<p >The - Hardware Requirements, Software Development and Installation guides should be reviewed before commencing development using this code.</p>
<p ><b>Testing</b></p>
<p >Test cases are available</p>
<p ><b>Releases</b></p>
<ul>
<li>Release v1.0 is the stable version of this work and it is available for installation here.</li>
</ul>
<p ><b>Documentation</b></p>
<p >This work is documented here for quick start. You can also check:</p>
<ul>
<li>Doxygen documentation [available here]().</li>
<li><a href="https://embedded-programming-team-18.github.io/blind-nav-system/">the page</a></li>
</ul>
<h1><a class="anchor" id="autotoc_md12"></a>
Installation</h1>
<p ><b>Downloading from GitHub</b></p>
<p >The following steps serve as a guide for installation after Pi image is installed and hardware is built/coupled.</p>
<ol type="1">
<li>To use this Library, the following needs to be installed on your Pi.</li>
</ol>
<div class="fragment"><div class="line">* PIGPIO: [this can be found here](https://abyz.me.uk/rpi/pigpio/download.html)</div>
<div class="line">* CMake</div>
</div><!-- fragment --><ol type="1">
<li>Enable Serioal port for <code>UART</code> on your Pi.</li>
<li>To compile and build the code after downloading from GitHub,</li>
</ol>
<div class="fragment"><div class="line">* Cmake .</div>
<div class="line">* Make</div>
</div><!-- fragment --><ol type="1">
<li>./blind-nav executable will be created.</li>
</ol>
<p ><b>Installing the library</b></p>
<h1><a class="anchor" id="autotoc_md13"></a>
Tests</h1>
<p >The following steps can be used to run the tests.</p>
<h1><a class="anchor" id="autotoc_md14"></a>
How to Use</h1>
<p >Using this work depends on your use case. In this repository, the <a class="el" href="class_lidar.html" title="The LiDAR class is a low-level driver for obtaining distance values needed for the functioning of the...">Lidar</a> library is designed to send its full scan <code>90 distance values</code> to a callback which is implemented depending on the use case. The smart glove implemented in this project shows this <a href="https://github.com/Embedded-programming-Team-18/blind-nav-system/blob/gh-pages/main.cpp">here</a>.</p>
<div class="fragment"><div class="line">class DataInterface : public Lidar::DataInterface {</div>
<div class="line">    void newScanAvail(int (&amp;data)[Lidar::nDistance]) {</div>
<div class="line">            // implement this callback function</div>
<div class="line"> </div>
<div class="line">        }</div>
<div class="line">}</div>
</div><!-- fragment --><p >To use the smart glove application, follow the installation guide Installation.</p>
<h1><a class="anchor" id="autotoc_md15"></a>
Contributing Guide</h1>
<p >'BLIND NAVIGATION SYSTEM' accepts PR's (pull requests) from <em>collaborators only</em> only. Issues can be submitted by any of the collaborators. <a href="https://github.com/EvelynAnyebe/blind-nav-system/blob/gh-pages/CONTRIBUTING.md">The contributing guide can be found here</a></p>
<h1><a class="anchor" id="autotoc_md16"></a>
Social Media</h1>
<p ><img src="https://res.cloudinary.com/dxsty3st6/image/upload/v1649395859/blind-nav-system/icons8-twitter-48_pt4icz.png" alt="twitter" class="inline"/> <img src="https://res.cloudinary.com/dxsty3st6/image/upload/v1649395859/blind-nav-system/icons8-instagram-48_k5kuwi.png" alt="instagram" class="inline"/> <img src="https://res.cloudinary.com/dxsty3st6/image/upload/v1649395859/blind-nav-system/icons8-youtube-48_kpall9.png" alt="youtube" class="inline"/></p>
<p >Find out more about the work on the following social media platforms:</p>
<ul>
<li><a href="https://twitter.com/BlindNav">twitter</a></li>
<li><a href="https://www.instagram.com/blindnavsystem/">instagram</a></li>
<li><a href="https://www.youtube.com/channel/UC3s1xHjyCuRFFpUrwtq7xhg">Youtube</a></li>
</ul>
<h1><a class="anchor" id="autotoc_md17"></a>
Credits</h1>
<ul>
<li>[Meghna Choudhury](Megna)</li>
<li>[Faiza Abdul Salam](Faiza)</li>
<li>[Abdul Ghani Zahid](Abdul)</li>
<li>[Evelyn Onyi Anyebe](Evelyn)</li>
</ul>
<h2><a class="anchor" id="autotoc_md18"></a>
Reference Links</h2>
<ul>
<li><a href="https://www.dfrobot.com/product-1702.html">dfrobot.com</a></li>
<li><a href="https://www.mygreatlearning.com/blog/readme-file/">README FILE-Everything you need to know</a></li>
<li><a href="https://github.com/berndporr/neato-xv11-lidar">berndporr/neato-xv11-lidar</a></li>
<li><a href="https://abyz.me.uk/rpi/pigpio">pigpio</a></li>
</ul>
<div class="fragment"><div class="line">Cheers!</div>
</div><!-- fragment --> </div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.3
</small></address>
</body>
</html>
